{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e4c557",
   "metadata": {},
   "source": [
    "# Figure 3: Hierarchical Invariant Template Detection Demo\n",
    "\n",
    "The code below demonstrates a (pre-calibrated) network for the hierarchical invariant template detection task, i.e. Algorithm 1 in the arXiv paper. It extracts motifs (as described in the appendix), then performs detections.\n",
    "\n",
    "The implementation is in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ebf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle imports\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from crab import hierarchy\n",
    "from hierarchy import extract_hierarchical, detect_hierarchical\n",
    "from matplotlib.image import imread\n",
    "import torch\n",
    "from torch import tensor\n",
    "from registration_pt import device, precision\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Setup\n",
    "data_path = '../data/detection_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0047be74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extraction: only needs to be run once.\n",
    "G = hierarchy(base_path = data_path)\n",
    "ext_spikes = extract_hierarchical(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb89523",
   "metadata": {},
   "source": [
    "## Helper functions: observation generation and plotting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dcaf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for generating an articulated crab observation\n",
    "# First some helper functions.\n",
    "# Various helper functions for testing, etc\n",
    "def draw_boxes(G, spikes, scene, out_fn=None):\n",
    "    \"\"\"Draw bounding boxes for a detection output\"\"\"\n",
    "\n",
    "    from matplotlib.image import imread\n",
    "\n",
    "    motifs = ['claw_left', 'claw_right', 'eye_left', 'eye_right', 'eye_pair',\n",
    "            'crab']\n",
    "    colors = {'claw_left': 'r',\n",
    "            'claw_right': 'r',\n",
    "            'eye_left': 'r',\n",
    "            'eye_right': 'r',\n",
    "            'eye_pair': 'g',\n",
    "            'crab': 'b'}\n",
    "    linewidths = {'claw_left': 1,\n",
    "            'claw_right': 1,\n",
    "            'eye_left': 1,\n",
    "            'eye_right': 1,\n",
    "            'eye_pair': 3,\n",
    "            'crab': 3}\n",
    "    vertical_pads = {'claw_left': 0,\n",
    "                     'claw_right': 0,\n",
    "                     'eye_left': 0,\n",
    "                     'eye_right': 0,\n",
    "                     'eye_pair': 15,\n",
    "                     'crab': 80}\n",
    "    horizontal_pads = {'claw_left': 0,\n",
    "                     'claw_right': 0,\n",
    "                     'eye_left': 0,\n",
    "                     'eye_right': 0,\n",
    "                     'eye_pair': 15,\n",
    "                     'crab': 40}\n",
    "\n",
    "    # show the scene\n",
    "    plt.imshow(scene)\n",
    "\n",
    "    # plot the bounding boxes specified in the detection results\n",
    "    for motif in motifs:\n",
    "        # 1. find the best detection index (smallest error)\n",
    "        errs = G.nodes[motif]['detection_dict']['errors'][:,-1]\n",
    "        best_idx = torch.argmin(errs)\n",
    "        \n",
    "        pad_shift = torch.tensor((vertical_pads[motif], horizontal_pads[motif]),\n",
    "                                 device='cpu', dtype=precision())\n",
    "\n",
    "        # 2. Plot the bounding box using parameters for this index\n",
    "        spikeloc_uncorr = G.nodes[motif]['detection_dict']['spike_locs'][best_idx,\n",
    "                :].to('cpu')\n",
    "        phi = G.nodes[motif]['detection_dict']['phi'][best_idx].to('cpu')\n",
    "        A = torch.tensor(((torch.cos(phi), -torch.sin(phi)), (torch.sin(phi),\n",
    "            torch.cos(phi))), device='cpu', dtype=precision())\n",
    "        C, M, N = G.nodes[motif]['content'][0].shape\n",
    "\n",
    "        dir_u = torch.tensor(((M-1)/2 + vertical_pads[motif], 0), device='cpu',\n",
    "                dtype=precision())\n",
    "        dir_v = torch.tensor((0, (N-1)/2 + horizontal_pads[motif]), device='cpu',\n",
    "                dtype=precision())\n",
    "        ctr = dir_u + dir_v\n",
    "        try:\n",
    "            articulation_pt = G.nodes[motif]['params']['articulation_pt'][0,...].to('cpu')\n",
    "        except KeyError:\n",
    "            articulation_pt = ctr\n",
    "        \n",
    "#        from pdb import set_trace\n",
    "#        set_trace()\n",
    "        corr_term = A @ (articulation_pt - ctr)\n",
    "        spikeloc = spikeloc_uncorr - corr_term\n",
    "\n",
    "        ul = - dir_u - dir_v\n",
    "        ur = - dir_u + dir_v\n",
    "        ll = dir_u - dir_v\n",
    "        lr = dir_u + dir_v\n",
    "\n",
    "        ul_new = (spikeloc + A @ ul).numpy()\n",
    "        ur_new = (spikeloc + A @ ur).numpy()\n",
    "        ll_new = (spikeloc + A @ ll).numpy()\n",
    "        lr_new = (spikeloc + A @ lr).numpy()\n",
    "\n",
    "        plt.plot( [ ul_new[1], ur_new[1], lr_new[1], ll_new[1], ul_new[1] ], [\n",
    "            ul_new[0], ur_new[0], lr_new[0], ll_new[0], ul_new[0] ], color =\n",
    "            colors[motif], linewidth = linewidths[motif] )\n",
    "\n",
    "    \n",
    "    # 3. Save the scene with all bounding boxes\n",
    "    ax = plt.gca()\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    if out_fn is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(out_fn + '_boxes.png')\n",
    "    plt.clf()\n",
    "\n",
    "    # 4. save crab detection trace to file too\n",
    "    trace = spikes[0,...].to('cpu').numpy()\n",
    "    markers, stems, base = plt.stem(np.sum(trace,-1))\n",
    "    plt.plot(np.ones_like(np.sum(trace,-1)), 'r--')\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([0.0, 1.5])\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    plt.setp(stems, 'linewidth', 2)\n",
    "    plt.setp(base, 'linewidth', 1)\n",
    "    plt.setp(markers, 'markersize', 4)\n",
    "    if out_fn is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(out_fn + '_trace.png')\n",
    "    plt.clf()\n",
    "\n",
    "# This isn't used, but can be used to create more scenes\n",
    "def make_beach_scene():\n",
    "    \"\"\"Create a scene of the crab on the beach\"\"\"\n",
    "\n",
    "    from data import crab_beach\n",
    "    from matplotlib.image import imsave\n",
    "\n",
    "    # Try to find a rotated crab\n",
    "    offset_u = 900\n",
    "    offset_v = 500\n",
    "    b = np.array((offset_u,offset_v))\n",
    "    phi = np.pi/8\n",
    "    A = np.array(((np.cos(phi), -np.sin(phi)), (np.sin(phi), np.cos(phi))))\n",
    "\n",
    "    scene = crab_beach(b, A=A)\n",
    "    sz_u = 384\n",
    "    sz_v = 512\n",
    "    scene_crop = scene[offset_u-100:offset_u-100+sz_u,\n",
    "            offset_v-100:offset_v-100+sz_v]\n",
    "\n",
    "    deg = np.round(10 * (phi / (np.pi / 180))) / 10\n",
    "    fn = 'crab_beach_' + str(deg) + 'deg.png'\n",
    "    imsave(fn, np.minimum(np.maximum(scene_crop, 0), 1))\n",
    "\n",
    "    pass\n",
    "\n",
    "# Simple timer class with context\n",
    "class Timer(object):\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.tstart = time.time()\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        if self.name:\n",
    "            print('[%s]' % self.name,)\n",
    "        print('Elapsed: %s' % (time.time() - self.tstart))\n",
    "\n",
    "\n",
    "def cconv_fourier(x, y):\n",
    "    \"\"\"Compute the circulant convolution of two images in Fourier space.\n",
    "\n",
    "    Implementing this on its own because scipy.signal.fftconvolve seems to\n",
    "    handle restriction in its 'same' mode incorrectly\n",
    "    \n",
    "    This function is implemented to work with potentially many-channel images:\n",
    "    it will just perform the 2D convolution on the *first two dimensions* of\n",
    "    the inputs. So permute dims if data is such that batch size/etc is first...\n",
    "\n",
    "    Requires:\n",
    "    x and y need to have the same shape / be broadcastable. (no automatic\n",
    "    padding)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    F_X = np.fft.fft2(x, axes=(0, 1), norm='backward')\n",
    "    F_Y = np.fft.fft2(y, axes=(0, 1), norm='backward')\n",
    "\n",
    "    F_XY = F_X * F_Y\n",
    "\n",
    "    return np.real(np.fft.ifft2(F_XY, axes=(0, 1)))\n",
    "\n",
    "def dsp_flip(X):\n",
    "    \"\"\"Compute the 'dsp flip' of input numpy tensor X\n",
    "\n",
    "    If X[i1, ..., ik] represents the input tensor, this function returns the\n",
    "    'dsp flipped' tensor X[-i1, ..., -ik], where all indexing is done modulo\n",
    "    the sizes of each individual dimension of X. So compared to the usual\n",
    "    flipud/fliplr (for matrices) flip, this leaves the first element in-place.\n",
    "\n",
    "    Inputs:\n",
    "    X : numpy array of any size\n",
    "\n",
    "    Outputs:\n",
    "    X with each dimension 'dsp flipped' as described above. Output type may be\n",
    "    float (not same as X)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Ndims = len(X.shape)\n",
    "    ax = tuple(range(Ndims)) * 2\n",
    "    # what's a log factor between friends?\n",
    "    return np.real(np.fft.fft2(X, axes=ax, norm='ortho'))\n",
    "\n",
    "def ncc(w, x, W=None):\n",
    "    \"\"\"Compute the normalized cross correlation between filter w and scene x\n",
    "\n",
    "    Assumptions:\n",
    "    1. w is \n",
    "\n",
    "    Inputs:\n",
    "    ---------\n",
    "    w - (m, n, C) numpy array\n",
    "        Filter. Smaller than x\n",
    "    x - (M, N, C) numpy array\n",
    "        Scene. larger than w\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    m, n, C = w.shape\n",
    "    M, N, C = x.shape\n",
    "\n",
    "    # patch summing filter\n",
    "    if W is None:\n",
    "        pad_W = np.zeros((M, N, C))\n",
    "        pad_W[:m, :n, :] = np.ones((C,))\n",
    "    else:\n",
    "        # passed a mask\n",
    "        pad_W = np.tile(W[...,None], (1, 1, 3))\n",
    "        pad_W = np.pad(pad_W, ((0, M-m), (0, N-n), (0,)*2))\n",
    "\n",
    "    # pad w\n",
    "    pad_w = np.pad(w, ((0, M-m), (0, N-n), (0,)*2))\n",
    "\n",
    "    # get scene patch norms\n",
    "    norms = np.maximum(0, np.sum(cconv_fourier(dsp_flip(pad_W), x**2), -1))**0.5\n",
    "\n",
    "    # get xcorr\n",
    "    xcorr = np.maximum(0, np.sum(cconv_fourier(dsp_flip(pad_w), x), -1))\n",
    "\n",
    "    # output\n",
    "    output = (1 / np.sum(w**2)**0.5) * (xcorr / norms)\n",
    "\n",
    "    # output checking: put -1 at nans\n",
    "    tol = 1e-6\n",
    "    output[norms < tol] = -1\n",
    "\n",
    "    return output\n",
    "\n",
    "def articulate_crab(xform_dict):\n",
    "    \"\"\"Make the crab's parts move independently!\n",
    "\n",
    "    TODO: Might make more sense to pass transformations as a hierarchical\n",
    "    structure or something\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    from matplotlib.image import imread\n",
    "    from registration_pt import resample_chunked\n",
    "    from images import imagesc, get_affine_grid\n",
    "\n",
    "    # overhead\n",
    "    dev = device()\n",
    "    prec = precision()\n",
    "    interp = lambda Y, tau: resample_chunked(torch.moveaxis(torch.tensor(Y,\n",
    "        device=dev, dtype=prec), -1, 0)[None, ...], tau, 128)[0, ...]\n",
    "    rot_mtx = lambda phi: torch.tensor(((torch.cos(phi),\n",
    "        -torch.sin(phi)),(torch.sin(phi), torch.cos(phi))), device=dev,\n",
    "        dtype=prec)\n",
    "    pi = torch.tensor(np.pi, device=dev, dtype=prec)\n",
    "\n",
    "    # Load template and motifs\n",
    "    data = imread(data_path + '/left_claw.png').astype('float64')\n",
    "    lc, lc_mask = (data[..., :-1], data[..., -1])\n",
    "    lc_mask = lc_mask[..., None]\n",
    "    data = imread(data_path + '/right_claw.png').astype('float64')\n",
    "    rc, rc_mask = (data[..., :-1], data[..., -1])\n",
    "    rc_mask = rc_mask[..., None]\n",
    "    data = imread(data_path + '/left_eye.png').astype('float64')\n",
    "    le, le_mask = (data[..., :-1], data[..., -1])\n",
    "    le_mask = le_mask[..., None]\n",
    "    data = imread(data_path + '/right_eye.png').astype('float64')\n",
    "    re, re_mask = (data[..., :-1], data[..., -1])\n",
    "    re_mask = re_mask[..., None]\n",
    "    data = imread(data_path + '/body.png').astype('float64')\n",
    "    body, body_mask = (data[..., :-1], data[..., -1])\n",
    "    body_mask = body_mask[..., None]\n",
    "    data = imread(data_path + '/crab.png').astype('float64')\n",
    "    crab, crab_mask = (data[..., :-1], data[..., -1])\n",
    "    crab_mask = crab_mask[..., None]\n",
    "\n",
    "    # Pad the template for convenience while articulating\n",
    "    pad_sz = 25\n",
    "    template = np.pad(crab, ((pad_sz,)*2,)*2 + ((0,0),))\n",
    "    template_mask = np.pad(crab_mask, ((pad_sz,)*2,)*2 + ((0,0),))\n",
    "\n",
    "    # Locate the motifs in the template using ncc\n",
    "    lc_ncc = ncc(lc, template)\n",
    "    lc_idx = np.unravel_index(np.argmax(lc_ncc), lc_ncc.shape)\n",
    "    rc_ncc = ncc(rc, template)\n",
    "    rc_idx = np.unravel_index(np.argmax(rc_ncc), rc_ncc.shape)\n",
    "    le_ncc = ncc(le, template)\n",
    "    le_idx = np.unravel_index(np.argmax(le_ncc), le_ncc.shape)\n",
    "    re_ncc = ncc(re, template)\n",
    "    re_idx = np.unravel_index(np.argmax(re_ncc), re_ncc.shape)\n",
    "    body_ncc = ncc(body, template)\n",
    "    body_idx = np.unravel_index(np.argmax(body_ncc), body_ncc.shape)\n",
    "\n",
    "    # Set up part transformation parameters\n",
    "    # Transformation grid mode: need to fix locs and centers (centers is for\n",
    "    # linked rigid body motion...)\n",
    "    # note: centers need to be 1x2\n",
    "    # note: use inverse parameterization?\n",
    "    m, n, c = template.shape\n",
    "    #lc_A = torch.eye(2, device=dev, dtype=prec)\n",
    "    lc_A = xform_dict['lc_A']\n",
    "    lc_b = torch.tensor(lc_idx, device=dev, dtype=prec)\n",
    "    lc_c = torch.tensor(((51, 38),), device=dev, dtype=prec)\n",
    "\n",
    "    # rc_A = torch.eye(2, device=dev, dtype=prec)\n",
    "    rc_A = xform_dict['rc_A']\n",
    "    rc_b = torch.tensor(rc_idx, device=dev, dtype=prec)\n",
    "    rc_c = torch.tensor(((45, 3),), device=dev, dtype=prec)\n",
    "\n",
    "    # le_A = torch.eye(2, device=dev, dtype=prec)\n",
    "    le_A = xform_dict['le_A']\n",
    "    le_b = torch.tensor(le_idx, device=dev, dtype=prec)\n",
    "    le_c = torch.tensor(((82, 4),), device=dev, dtype=prec)\n",
    "\n",
    "    # re_A = torch.eye(2, device=dev, dtype=prec)\n",
    "    re_A = xform_dict['re_A']\n",
    "    re_b = torch.tensor(re_idx, device=dev, dtype=prec)\n",
    "    re_c = torch.tensor(((81, 4),), device=dev, dtype=prec)\n",
    "\n",
    "    body_A = torch.eye(2, device=dev, dtype=prec)\n",
    "    body_b = torch.tensor(body_idx, device=dev, dtype=prec)\n",
    "    body_c = torch.zeros((1,2), device=dev, dtype=prec)\n",
    "\n",
    "    template_A = xform_dict['template_A']\n",
    "    template_b = xform_dict['template_b']\n",
    "    # Make grids\n",
    "    loc = torch.zeros((1,2), device=dev, dtype=prec)\n",
    "    M, N, C = lc.shape\n",
    "    lc_grid = get_affine_grid((lc_A.T)[None,...], -torch.flip(lc_A.T @\n",
    "        lc_b, (-1,))[None,...], M, N, m, n, locs=loc, ctrs=lc_c)\n",
    "    M, N, C = rc.shape\n",
    "    rc_grid = get_affine_grid((rc_A.T)[None,...], -torch.flip(rc_A.T @\n",
    "        rc_b, (-1,))[None,...], M, N, m, n, locs=loc, ctrs=rc_c)\n",
    "    M, N, C = le.shape\n",
    "    le_grid = get_affine_grid((le_A.T)[None,...], -torch.flip(le_A.T @\n",
    "        le_b, (-1,))[None,...], M, N, m, n, locs=loc, ctrs=le_c)\n",
    "    le_grid_2 = get_affine_grid((le_A.T)[None,...], torch.zeros((2,),\n",
    "        device=dev, dtype=prec)[None,...], M, N, M, M, locs=loc, ctrs=loc)\n",
    "    M, N, C = re.shape\n",
    "    re_grid = get_affine_grid((re_A.T)[None,...], -torch.flip(re_A.T @\n",
    "        re_b, (-1,))[None,...], M, N, m, n, locs=loc, ctrs=re_c)\n",
    "    M, N, C = body.shape\n",
    "    body_grid = get_affine_grid((body_A.T)[None,...], \n",
    "        -torch.flip(body_A.T @ body_b, (-1,))[None,...], M, N, m, n, locs=loc,\n",
    "        ctrs=body_c)\n",
    "    template_grid = get_affine_grid((template_A.T)[None, ...], template_b[None,\n",
    "        ...], m, n, m, n)\n",
    "\n",
    "    # Test to see if we can regenerate the template from these locations\n",
    "    instance = (interp(lc, lc_grid) + interp(rc, rc_grid) + interp(le, le_grid)\n",
    "            + interp(re, re_grid) + interp(body, body_grid))\n",
    "    instance_mask = (interp(lc_mask, lc_grid) + interp(rc_mask, rc_grid) +\n",
    "            interp(le_mask, le_grid) + interp(re_mask, re_grid) +\n",
    "            interp(body_mask, body_grid))\n",
    "    # Global transformation of the frame\n",
    "    instance = resample_chunked(instance[None, ...], template_grid, 128)[0,\n",
    "            ...]\n",
    "    instance_mask = resample_chunked(instance_mask[None, ...], template_grid,\n",
    "            128)[0, ...]\n",
    "    # clamping\n",
    "    instance = torch.clamp(instance, min=0.0, max=1.0)\n",
    "    instance_mask = torch.clamp(instance_mask, min=0.0, max=1.0)\n",
    "    instance_mask = torch.round(instance_mask)\n",
    "    instance *= instance_mask\n",
    "\n",
    "    return instance, instance_mask\n",
    "\n",
    "def create_observation(xform_dict):\n",
    "    \"\"\"\n",
    "    Demo the articulated crab\n",
    "    \"\"\"\n",
    "    from images import imagesc, get_affine_grid\n",
    "    from matplotlib.image import imread, imsave\n",
    "    from registration_pt import resample_chunked\n",
    "\n",
    "    dev = device()\n",
    "    prec = precision()\n",
    "    rot_mtx = lambda phi: torch.tensor(((torch.cos(phi),\n",
    "        -torch.sin(phi)),(torch.sin(phi), torch.cos(phi))), device=dev,\n",
    "        dtype=prec)\n",
    "    pi = torch.tensor(np.pi, device=dev, dtype=prec)\n",
    "    interp = lambda Y, tau: resample_chunked(Y[None, ...], tau, 128)[0, ...]\n",
    "\n",
    "\n",
    "    # Get beach background\n",
    "    beach_bg = imread(data_path + '/beach_bg.jpg')\n",
    "    beach_bg = 1/255 * beach_bg.astype('float64')\n",
    "    beach_bg = torch.moveaxis(torch.tensor(beach_bg, device=dev, dtype=prec),\n",
    "            -1, 0)\n",
    "\n",
    "    # Embed template instance\n",
    "    embed_u = 950\n",
    "    embed_v = 600\n",
    "    \n",
    "    target_W = 512\n",
    "    target_H = 384\n",
    "\n",
    "    # Get template instance\n",
    "    instance, instance_mask = articulate_crab(xform_dict)\n",
    "    instance = torch.nn.functional.pad(instance, ((target_W - instance.shape[2])//2,\n",
    "                                                  (target_W - instance.shape[2])//2 + instance.shape[2] % 2,\n",
    "                                                  (target_H - instance.shape[1])//2,\n",
    "                                                  (target_H - instance.shape[1])//2 + instance.shape[1] % 2))\n",
    "    instance_mask = torch.nn.functional.pad(instance_mask, ((target_W - instance_mask.shape[2])//2,\n",
    "                                                  (target_W - instance_mask.shape[2])//2 + instance_mask.shape[2] % 2,\n",
    "                                                  (target_H - instance_mask.shape[1])//2,\n",
    "                                                  (target_H - instance_mask.shape[1])//2 + instance_mask.shape[1] % 2))\n",
    "    embed_coords = torch.tensor((embed_u, embed_v), device=dev, dtype=prec)\n",
    "    grid_scene = get_affine_grid(torch.eye(2, device=dev,\n",
    "        dtype=prec)[None,...], torch.zeros((2,), device=dev,\n",
    "            dtype=prec)[None, :], beach_bg.shape[1], beach_bg.shape[2],\n",
    "        target_H, target_W, locs=embed_coords[None, :])\n",
    "    \n",
    "    image_iter = 0\n",
    "    bg_crop = interp(beach_bg, grid_scene)\n",
    "    scene = torch.clamp(instance_mask * instance + (1.0 - instance_mask) *\n",
    "            bg_crop, max=1.0, min=0.0)\n",
    "    # imsave(f'test.png', torch.moveaxis(scene, 0,\n",
    "    #    -1).to('cpu').numpy())\n",
    "    \n",
    "    return scene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b747181",
   "metadata": {},
   "source": [
    "## Evaluating the calibrated model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06efc1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some observations\n",
    "dev = device()\n",
    "prec = precision()\n",
    "rot_mtx = lambda phi: torch.tensor(((torch.cos(phi),\n",
    "    -torch.sin(phi)),(torch.sin(phi), torch.cos(phi))), device=dev,\n",
    "    dtype=prec)\n",
    "pi = torch.tensor(np.pi, device=dev, dtype=prec)\n",
    "\n",
    "# Initialize\n",
    "xform_dict = {}\n",
    "xform_dict['lc_A'] = rot_mtx(0*pi)\n",
    "xform_dict['rc_A'] = rot_mtx(0*pi)\n",
    "xform_dict['le_A'] = rot_mtx(0*pi)\n",
    "xform_dict['re_A'] = rot_mtx(0*pi)\n",
    "xform_dict['template_A'] = rot_mtx(0*pi)\n",
    "xform_dict['template_b'] = torch.zeros((2,), device=dev, dtype=prec)\n",
    "\n",
    "# index to tranform dict keys... scan over 5 keys\n",
    "idx_to_keys = ['lc_A', 'rc_A', 'le_A', 're_A', 'template_A']\n",
    "\n",
    "# scan parameters\n",
    "max_deg = 30\n",
    "num_side = 3\n",
    "rot_sizes = torch.linspace(-max_deg, max_deg, 2*num_side + 1, device=dev, dtype=prec)\n",
    "if num_side == 0:\n",
    "    rot_sizes = torch.tensor((0*pi,), device=dev, dtype=prec)\n",
    "rot_sizes_rads = rot_sizes * pi / 180\n",
    "max_deg_parts = 15\n",
    "num_side_parts = 0\n",
    "rot_sizes_parts = torch.linspace(-max_deg_parts, max_deg_parts,\n",
    "                                 2*num_side_parts + 1, device=dev, dtype=prec)\n",
    "if num_side_parts == 0:\n",
    "    rot_sizes_parts = torch.tensor((0*pi,), device=dev, dtype=prec)\n",
    "rot_sizes_rads_parts = rot_sizes_parts * pi / 180\n",
    "\n",
    "\n",
    "# logging\n",
    "fn_prefix = 'detection_results/'\n",
    "detection_results = torch.zeros((2*num_side_parts+1,)*4 + (2*num_side+1,),\n",
    "                               device=dev, dtype=prec)\n",
    "\n",
    "# Perform scan experiment.\n",
    "for lc_idx in range(2*num_side_parts+1):\n",
    "    #xform_dict['lc_A'] = rot_mtx(rot_sizes_rads_parts[lc_idx])\n",
    "    xform_dict['lc_A'] = rot_mtx(pi/12)\n",
    "    for rc_idx in range(2*num_side_parts+1):\n",
    "        #xform_dict['rc_A'] = rot_mtx(rot_sizes_rads_parts[rc_idx])\n",
    "        xform_dict['rc_A'] = rot_mtx(-pi/12)\n",
    "        for le_idx in range(2*num_side_parts+1):\n",
    "            #xform_dict['le_A'] = rot_mtx(rot_sizes_rads_parts[le_idx])\n",
    "            xform_dict['le_A'] = rot_mtx(pi/36)\n",
    "            for re_idx in range(2*num_side_parts+1):\n",
    "                #xform_dict['re_A'] = rot_mtx(rot_sizes_rads_parts[re_idx])\n",
    "                xform_dict['re_A'] = rot_mtx(-pi/36)\n",
    "                for c_idx in range(2*num_side+1):\n",
    "                    xform_dict['template_A'] = rot_mtx(rot_sizes_rads[c_idx])\n",
    "                    \n",
    "                    scene_art = create_observation(xform_dict)\n",
    "\n",
    "                    with Timer('timing detection...'):\n",
    "                        spikes_art = detect_hierarchical(scene_art, G)\n",
    "                    detection_results[lc_idx,rc_idx,le_idx,re_idx,c_idx] = spikes_art.sum()\n",
    "\n",
    "                    # Visualize results\n",
    "                    draw_boxes(G, spikes_art,\n",
    "                               torch.moveaxis(scene_art, 0, -1).to('cpu').numpy(),\n",
    "                               out_fn=fn_prefix + f'run{lc_idx}{rc_idx}{le_idx}{re_idx}{c_idx}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
