{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e4c557",
   "metadata": {},
   "source": [
    "# Figure 3: Hierarchical Invariant Template Detection Demo\n",
    "\n",
    "The code below demonstrates a (pre-calibrated) network for the hierarchical invariant template detection task, i.e. Algorithm 1 in the arXiv paper. It extracts motifs (as described in the appendix), then performs detections.\n",
    "\n",
    "The implementation is in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8ebf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle imports\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from crab import hierarchy\n",
    "from hierarchy import extract_hierarchical, detect_hierarchical\n",
    "from matplotlib.image import imread\n",
    "import torch\n",
    "from torch import tensor\n",
    "from registration_pt import device, precision\n",
    "import time\n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0047be74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing motif eye_left.\n",
      "Extracting motif eye_left with calibrated params.\n",
      "Total work to do: 72 strides, at 90 by 30 motif, in 184 by 246 scene.\n",
      "Motif eye_left extraction complete.\n",
      "Spike map norm (want 1): 1.0\n",
      "Processing motif eye_right.\n",
      "Extracting motif eye_right with calibrated params.\n",
      "Total work to do: 78 strides, at 93 by 21 motif, in 184 by 246 scene.\n",
      "Motif eye_right extraction complete.\n",
      "Spike map norm (want 1): 1.0000002364209042\n",
      "Processing motif claw_left.\n",
      "Extracting motif claw_left with calibrated params.\n",
      "Total work to do: 88 strides, at 61 by 56 motif, in 184 by 246 scene.\n",
      "Motif claw_left extraction complete.\n",
      "Spike map norm (want 1): 1.0000000249298016\n",
      "Processing motif claw_right.\n",
      "Extracting motif claw_right with calibrated params.\n",
      "Total work to do: 77 strides, at 68 by 60 motif, in 184 by 246 scene.\n",
      "Motif claw_right extraction complete.\n",
      "Spike map norm (want 1): 1.0000000000004563\n",
      "Processing motif eye_pair.\n",
      "Extracting motif eye_pair with calibrated params.\n",
      "Total work to do: 72 strides, at 93 by 40 motif, in 184 by 246 scene.\n",
      "4 accepted strides (rejecting at level 0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/projects/python/refine/experiments/../src/hierarchy.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  occ_mask = tensor(torch.sum(occ_map,0)[None,...] >\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motif eye_pair extraction complete.\n",
      "Spike map norm (want 1): 1.0000012855325078\n",
      "Processing motif crab.\n",
      "Extracting motif crab with calibrated params.\n",
      "Total work to do: 24 strides, at 92 by 190 motif, in 184 by 246 scene.\n",
      "5 accepted strides (rejecting at level 0.2)\n",
      "Motif crab extraction complete.\n",
      "Spike map norm (want 1): 1.0007884577753123\n"
     ]
    }
   ],
   "source": [
    "# Extraction: only needs to be run once.\n",
    "G = hierarchy()\n",
    "flag = extract_hierarchical(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb89523",
   "metadata": {},
   "source": [
    "## Transformation options\n",
    "Edit in the next cell to test detections with a different rotation magnitude of the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe3b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different scenes available (global rotations of crab)\n",
    "#scene = imread('../data/crab_beach_0.0deg.png')\n",
    "scene = imread('../data/crab_beach_7.5deg.png')\n",
    "#scene = imread('../data/crab_beach_15.0deg.png')\n",
    "#scene = imread('../data/crab_beach_22.5deg.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11203fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various helper functions for testing, etc\n",
    "def draw_boxes(G, spikes, scene):\n",
    "    \"\"\"Draw bounding boxes for a detection output\"\"\"\n",
    "\n",
    "    from matplotlib.image import imread\n",
    "\n",
    "    motifs = ['claw_left', 'claw_right', 'eye_left', 'eye_right', 'eye_pair',\n",
    "            'crab']\n",
    "    colors = {'claw_left': 'r',\n",
    "            'claw_right': 'r',\n",
    "            'eye_left': 'r',\n",
    "            'eye_right': 'r',\n",
    "            'eye_pair': 'g',\n",
    "            'crab': 'b'}\n",
    "    linewidths = {'claw_left': 1,\n",
    "            'claw_right': 1,\n",
    "            'eye_left': 1,\n",
    "            'eye_right': 1,\n",
    "            'eye_pair': 3,\n",
    "            'crab': 3}\n",
    "\n",
    "    # show the scene\n",
    "    plt.imshow(scene)\n",
    "\n",
    "    # plot the bounding boxes specified in the detection results\n",
    "    for motif in motifs:\n",
    "        # 1. find the best detection index (smallest error)\n",
    "        errs = G.nodes[motif]['detection_dict']['errors'][:,-1]\n",
    "        best_idx = torch.argmin(errs)\n",
    "\n",
    "        # 2. Plot the bounding box using parameters for this index\n",
    "        spikeloc = G.nodes[motif]['detection_dict']['spike_locs'][best_idx,\n",
    "                :].to('cpu')\n",
    "        phi = G.nodes[motif]['detection_dict']['phi'][best_idx].to('cpu')\n",
    "        A = torch.tensor(((torch.cos(phi), -torch.sin(phi)), (torch.sin(phi),\n",
    "            torch.cos(phi))), device='cpu', dtype=precision())\n",
    "        C, M, N = G.nodes[motif]['content'][0].shape\n",
    "\n",
    "        dir_u = torch.tensor(((M-1)/2, 0), device='cpu',\n",
    "                dtype=precision())\n",
    "        dir_v = torch.tensor((0, (N-1)/2), device='cpu',\n",
    "                dtype=precision())\n",
    "        ctr = dir_u + dir_v\n",
    "\n",
    "        ul = - dir_u - dir_v\n",
    "        ur = - dir_u + dir_v\n",
    "        ll = dir_u - dir_v\n",
    "        lr = dir_u + dir_v\n",
    "\n",
    "        ul_new = (spikeloc + A @ ul).numpy()\n",
    "        ur_new = (spikeloc + A @ ur).numpy()\n",
    "        ll_new = (spikeloc + A @ ll).numpy()\n",
    "        lr_new = (spikeloc + A @ lr).numpy()\n",
    "\n",
    "        plt.plot( [ ul_new[1], ur_new[1], lr_new[1], ll_new[1], ul_new[1] ], [\n",
    "            ul_new[0], ur_new[0], lr_new[0], ll_new[0], ul_new[0] ], color =\n",
    "            colors[motif], linewidth = linewidths[motif] )\n",
    "\n",
    "    \n",
    "    # 3. Save the scene with all bounding boxes\n",
    "    ax = plt.gca()\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    # 4. save crab detection trace to file too\n",
    "    trace = spikes[0,...].to('cpu').numpy()\n",
    "    markers, stems, base = plt.stem(np.sum(trace,-1))\n",
    "    ax = plt.gca()\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    plt.setp(stems, 'linewidth', 2)\n",
    "    plt.setp(base, 'linewidth', 1)\n",
    "    plt.setp(markers, 'markersize', 4)\n",
    "    plt.show()\n",
    "\n",
    "# This isn't used, but can be used to create more scenes\n",
    "def make_beach_scene():\n",
    "    \"\"\"Create a scene of the crab on the beach\"\"\"\n",
    "\n",
    "    from data import crab_beach\n",
    "    from matplotlib.image import imsave\n",
    "\n",
    "    # Try to find a rotated crab\n",
    "    offset_u = 900\n",
    "    offset_v = 500\n",
    "    b = np.array((offset_u,offset_v))\n",
    "    phi = np.pi/8\n",
    "    A = np.array(((np.cos(phi), -np.sin(phi)), (np.sin(phi), np.cos(phi))))\n",
    "\n",
    "    scene = crab_beach(b, A=A)\n",
    "    sz_u = 384\n",
    "    sz_v = 512\n",
    "    scene_crop = scene[offset_u-100:offset_u-100+sz_u,\n",
    "            offset_v-100:offset_v-100+sz_v]\n",
    "\n",
    "    deg = np.round(10 * (phi / (np.pi / 180))) / 10\n",
    "    fn = 'crab_beach_' + str(deg) + 'deg.png'\n",
    "    imsave(fn, np.minimum(np.maximum(scene_crop, 0), 1))\n",
    "\n",
    "    pass\n",
    "\n",
    "# Simple timer class with context\n",
    "class Timer(object):\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.tstart = time.time()\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        if self.name:\n",
    "            print('[%s]' % self.name,)\n",
    "        print('Elapsed: %s' % (time.time() - self.tstart))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921b5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing motif eye_left.\n",
      "Total work to do: 416 strides, at 90 by 30 motif, in 384 by 512 scene.\n",
      "Motif eye_left detection complete.\n",
      "Spike map norm (want 1): 1.0205832235923191\n",
      "Processing motif eye_right.\n",
      "Total work to do: 416 strides, at 93 by 21 motif, in 384 by 512 scene.\n",
      "Motif eye_right detection complete.\n",
      "Spike map norm (want 1): 1.0000000000003424\n",
      "Processing motif claw_left.\n",
      "Total work to do: 432 strides, at 61 by 56 motif, in 384 by 512 scene.\n",
      "Motif claw_left detection complete.\n",
      "Spike map norm (want 1): 1.0000003250179685\n",
      "Processing motif claw_right.\n",
      "Total work to do: 408 strides, at 68 by 60 motif, in 384 by 512 scene.\n",
      "Motif claw_right detection complete.\n",
      "Spike map norm (want 1): 1.066920124115021\n",
      "Processing motif eye_pair.\n",
      "Total work to do: 400 strides, at 93 by 40 motif, in 384 by 512 scene.\n",
      "12 accepted strides (rejecting at level 0.2)\n",
      "Motif eye_pair detection complete.\n",
      "Spike map norm (want 1): 1.0009738952312832\n",
      "Processing motif crab.\n",
      "Total work to do: 288 strides, at 92 by 190 motif, in 384 by 512 scene.\n",
      "6 accepted strides (rejecting at level 0.2)\n"
     ]
    }
   ],
   "source": [
    "# Code for detection, given the selected scene.\n",
    "scene = scene[..., 0:3]\n",
    "dev = device()\n",
    "Y = torch.tensor(scene, device=dev, dtype=precision())\n",
    "Y = torch.moveaxis(Y, -1, 0)\n",
    "\n",
    "with Timer('timing detection...'):\n",
    "    spikes = detect_hierarchical(Y, G)\n",
    "\n",
    "# Visualize results\n",
    "draw_boxes(G, spikes, scene)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
